{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d7fd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optuna import 추가\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "def objective(trial, x, y, building_type):\n",
    "    \"\"\"\n",
    "    Optuna objective function for LightGBM hyperparameter optimization\n",
    "    \"\"\"\n",
    "    # 파라미터 제안\n",
    "    params = {\n",
    "        'learning_rate': 0.05,  # 고정\n",
    "        'n_estimators': 5000,   # 고정 (early stopping 사용)\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'feature_fraction': trial.suggest_float('feature_fraction', 0.6, 1.0),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 50),\n",
    "        'alpha': trial.suggest_float('alpha', 0.5, 3.0),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 2.0),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 2.0),\n",
    "        'min_gain_to_split': trial.suggest_float('min_gain_to_split', 0.0, 1.0),\n",
    "        'random_state': RANDOM_SEED,\n",
    "        'device': 'gpu',\n",
    "        'verbosity': -1\n",
    "    }\n",
    "    \n",
    "    # 교차검증\n",
    "    kf_opt = KFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)\n",
    "    smape_scores = []\n",
    "    \n",
    "    for train_idx, val_idx in kf_opt.split(x):\n",
    "        X_train, X_val = x.iloc[train_idx], x.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        \n",
    "        # log1p 변환\n",
    "        y_train_t = np.log1p(np.clip(y_train, a_min=0, a_max=None))\n",
    "        y_val_t = np.log1p(np.clip(y_val, a_min=0, a_max=None))\n",
    "        \n",
    "        model = LGBMRegressor(\n",
    "            learning_rate=params['learning_rate'],\n",
    "            n_estimators=params['n_estimators'],\n",
    "            max_depth=params['max_depth'],\n",
    "            subsample=params['subsample'],\n",
    "            feature_fraction=params['feature_fraction'],\n",
    "            min_child_samples=params['min_child_samples'],\n",
    "            reg_alpha=params['reg_alpha'],\n",
    "            reg_lambda=params['reg_lambda'],\n",
    "            min_gain_to_split=params['min_gain_to_split'],\n",
    "            objective=weighted_mse_lgb(params['alpha']),\n",
    "            random_state=params['random_state'],\n",
    "            device=params['device'],\n",
    "            verbosity=params['verbosity']\n",
    "        )\n",
    "        \n",
    "        model.fit(\n",
    "            X_train, y_train_t,\n",
    "            eval_set=[(X_val, y_val_t)],\n",
    "            callbacks=[lightgbm.early_stopping(50), lightgbm.log_evaluation(0)]\n",
    "        )\n",
    "        \n",
    "        # 예측 및 SMAPE 계산\n",
    "        pred_t = model.predict(X_val)\n",
    "        pred = np.expm1(pred_t)\n",
    "        score = smape(y_val.values, pred)\n",
    "        smape_scores.append(score)\n",
    "    \n",
    "    return np.mean(smape_scores)\n",
    "\n",
    "# 건물 타입별 최적화 실행\n",
    "def optimize_parameters():\n",
    "    \"\"\"\n",
    "    각 건물 타입별로 파라미터 최적화 수행\n",
    "    \"\"\"\n",
    "    best_params_dict = {}\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"Optuna를 이용한 건물 타입별 하이퍼파라미터 최적화 시작\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for i, building_type in enumerate(type_list):\n",
    "        print(f\"\\n[{i+1}/{len(type_list)}] 건물 타입: {building_type} 최적화 중...\")\n",
    "        \n",
    "        # 데이터 준비\n",
    "        x = X[X.building_type == building_type].copy()\n",
    "        y = Y[Y.building_type == building_type]['power_consumption'].astype(float).copy()\n",
    "        \n",
    "        # 라벨 클린업\n",
    "        y = y.replace([np.inf, -np.inf], np.nan)\n",
    "        ok = y.notna() & (y >= 0)\n",
    "        if not ok.all():\n",
    "            x = x.loc[ok]\n",
    "            y = y.loc[ok]\n",
    "        \n",
    "        # 원핫 인코딩\n",
    "        x_encoded = pd.get_dummies(x, columns=['building_number'], drop_first=False)\n",
    "        \n",
    "        # building_type 컬럼 제거\n",
    "        if 'building_type' in x_encoded.columns:\n",
    "            x_encoded.drop(columns=['building_type'], inplace=True)\n",
    "        \n",
    "        # NaN/Inf 처리\n",
    "        x_encoded = x_encoded.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "        x_encoded = x_encoded.astype(np.float32)\n",
    "        y = y.astype(np.float32)\n",
    "        \n",
    "        # 데이터가 너무 적으면 스킵\n",
    "        if len(x_encoded) < 100:\n",
    "            print(f\"  데이터가 부족합니다 ({len(x_encoded)}개). 기본 파라미터 사용.\")\n",
    "            best_params_dict[building_type] = {\n",
    "                'max_depth': 8,\n",
    "                'subsample': 0.8,\n",
    "                'feature_fraction': 0.8,\n",
    "                'min_child_samples': 20,\n",
    "                'alpha': 1.5,\n",
    "                'reg_alpha': 0.1,\n",
    "                'reg_lambda': 0.1,\n",
    "                'min_gain_to_split': 0.0\n",
    "            }\n",
    "            continue\n",
    "        \n",
    "        # Optuna 최적화\n",
    "        sampler = TPESampler(seed=RANDOM_SEED)\n",
    "        study = optuna.create_study(direction='minimize', sampler=sampler)\n",
    "        \n",
    "        # 최적화 실행 (시간 단축을 위해 trials 수 조정)\n",
    "        n_trials = 50 if len(x_encoded) > 1000 else 30\n",
    "        \n",
    "        try:\n",
    "            study.optimize(\n",
    "                lambda trial: objective(trial, x_encoded, y, building_type),\n",
    "                n_trials=n_trials,\n",
    "                timeout=1800,  # 30분 제한\n",
    "                show_progress_bar=True\n",
    "            )\n",
    "            \n",
    "            best_params = study.best_params\n",
    "            best_score = study.best_value\n",
    "            \n",
    "            print(f\"  최적 SMAPE: {best_score:.4f}\")\n",
    "            print(f\"  최적 파라미터: {best_params}\")\n",
    "            \n",
    "            best_params_dict[building_type] = best_params\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  최적화 중 오류 발생: {e}\")\n",
    "            # 기본 파라미터 사용\n",
    "            best_params_dict[building_type] = {\n",
    "                'max_depth': 8,\n",
    "                'subsample': 0.8,\n",
    "                'feature_fraction': 0.8,\n",
    "                'min_child_samples': 20,\n",
    "                'alpha': 1.5,\n",
    "                'reg_alpha': 0.1,\n",
    "                'reg_lambda': 0.1,\n",
    "                'min_gain_to_split': 0.0\n",
    "            }\n",
    "    \n",
    "    # 결과를 DataFrame으로 변환하여 저장\n",
    "    params_df = pd.DataFrame(best_params_dict).T\n",
    "    params_df.reset_index(inplace=True)\n",
    "    params_df.rename(columns={'index': 'building_type'}, inplace=True)\n",
    "    params_df.to_csv('lgb_best_params_found.csv', index=False)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"최적화 완료! 결과가 'lgb_best_params_found.csv'에 저장되었습니다.\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    return params_df\n",
    "\n",
    "# 최적화 실행\n",
    "if __name__ == \"__main__\":\n",
    "    # 기존에 최적화된 파일이 있는지 확인\n",
    "    import os\n",
    "    if os.path.exists('lgb_best_params_found.csv'):\n",
    "        print(\"기존 최적화 파일이 발견되었습니다.\")\n",
    "        use_existing = input(\"기존 파일을 사용하시겠습니까? (y/n): \")\n",
    "        if use_existing.lower() != 'y':\n",
    "            lgb_best_params = optimize_parameters()\n",
    "        else:\n",
    "            lgb_best_params = pd.read_csv('lgb_best_params_found.csv')\n",
    "    else:\n",
    "        lgb_best_params = optimize_parameters()\n",
    "    \n",
    "    # 인덱스 설정\n",
    "    lgb_best_params.set_index('building_type', inplace=True)\n",
    "    print(\"\\n최적화된 파라미터:\")\n",
    "    print(lgb_best_params)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
