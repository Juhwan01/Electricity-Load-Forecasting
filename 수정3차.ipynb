{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2606838c",
   "metadata": {},
   "source": [
    "# 함수 선언 및  import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a527ea83",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-01T12:15:59.117024Z",
     "start_time": "2023-09-01T12:15:59.110018Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "\n",
    "import sklearn\n",
    "import xgboost\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import random as rn\n",
    "\n",
    "RANDOM_SEED = 2024\n",
    "np.random.seed(RANDOM_SEED)\n",
    "rn.seed(RANDOM_SEED)\n",
    "\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213bb3e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-01T12:16:06.920627Z",
     "start_time": "2023-09-01T12:16:06.916624Z"
    }
   },
   "outputs": [],
   "source": [
    "def smape(gt, preds):\n",
    "    gt= np.array(gt)\n",
    "    preds = np.array(preds)\n",
    "    v = 2 * abs(preds - gt) / (abs(preds) + abs(gt))\n",
    "    score = np.mean(v) * 100\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3ed4c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-01T12:16:07.296669Z",
     "start_time": "2023-09-01T12:16:07.280654Z"
    }
   },
   "outputs": [],
   "source": [
    "def weighted_mse(alpha = 1):\n",
    "    def weighted_mse_fixed(label, pred):\n",
    "        residual = (label - pred).astype(\"float\")\n",
    "        grad = np.where(residual>0, -2*alpha*residual, -2*residual)\n",
    "        hess = np.where(residual>0, 2*alpha, 2.0)\n",
    "        return grad, hess\n",
    "    return weighted_mse_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130a94d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-01T12:16:08.919122Z",
     "start_time": "2023-09-01T12:16:08.904108Z"
    }
   },
   "outputs": [],
   "source": [
    "def custom_smape(preds, dtrain):\n",
    "    labels_t = dtrain.get_label()              # log1p 라벨\n",
    "    preds_t  = preds                           # log1p 예측\n",
    "    labels_o = np.expm1(labels_t)              # 원 스케일\n",
    "    preds_o  = np.expm1(preds_t)\n",
    "    denom = np.abs(preds_o) + np.abs(labels_o)\n",
    "    smape_val = 100.0 * np.mean((2.0 * np.abs(preds_o - labels_o)) / np.maximum(denom, 1e-9))\n",
    "    return 'custom_smape', float(smape_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c93aad7",
   "metadata": {},
   "source": [
    "# 데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59754f5d",
   "metadata": {},
   "source": [
    "## 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e49868",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-01T09:55:54.861486Z",
     "start_time": "2023-09-01T09:55:54.703696Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "building_info = pd.read_csv('building_info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ddf770",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-01T09:55:54.966582Z",
     "start_time": "2023-09-01T09:55:54.940559Z"
    }
   },
   "outputs": [],
   "source": [
    "train = train.rename(columns={\n",
    "    '건물번호': 'building_number',\n",
    "    '일시': 'date_time',\n",
    "    '기온(°C)': 'temperature',\n",
    "    '강수량(mm)': 'rainfall',\n",
    "    '풍속(m/s)': 'windspeed',\n",
    "    '습도(%)': 'humidity',\n",
    "    '일조(hr)': 'sunshine',\n",
    "    '일사(MJ/m2)': 'solar_radiation',\n",
    "    '전력소비량(kWh)': 'power_consumption'\n",
    "})\n",
    "train.drop('num_date_time', axis = 1, inplace=True)\n",
    "\n",
    "test = test.rename(columns={\n",
    "    '건물번호': 'building_number',\n",
    "    '일시': 'date_time',\n",
    "    '기온(°C)': 'temperature',\n",
    "    '강수량(mm)': 'rainfall',\n",
    "    '풍속(m/s)': 'windspeed',\n",
    "    '습도(%)': 'humidity',\n",
    "    '일조(hr)': 'sunshine',\n",
    "    '일사(MJ/m2)': 'solar_radiation',\n",
    "    '전력소비량(kWh)': 'power_consumption'\n",
    "})\n",
    "test.drop('num_date_time', axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c0d646",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-01T09:55:55.116716Z",
     "start_time": "2023-09-01T09:55:55.108709Z"
    }
   },
   "outputs": [],
   "source": [
    "building_info = building_info.rename(columns={\n",
    "    '건물번호': 'building_number',\n",
    "    '건물유형': 'building_type',\n",
    "    '연면적(m2)': 'total_area',\n",
    "    '냉방면적(m2)': 'cooling_area',\n",
    "    '태양광용량(kW)': 'solar_power_capacity',\n",
    "    'ESS저장용량(kWh)': 'ess_capacity',\n",
    "    'PCS용량(kW)': 'pcs_capacity'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c36f788",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-01T09:55:55.281867Z",
     "start_time": "2023-09-01T09:55:55.263850Z"
    }
   },
   "outputs": [],
   "source": [
    "translation_dict = {\n",
    "    '건물기타': 'Other Buildings',\n",
    "    '공공': 'Public',\n",
    "    '대학교': 'University',\n",
    "    '데이터센터': 'Data Center',\n",
    "    '백화점및아울렛': 'Department Store and Outlet',\n",
    "    '병원': 'Hospital',\n",
    "    '상용': 'Commercial',\n",
    "    '아파트': 'Apartment',\n",
    "    '연구소': 'Research Institute',\n",
    "    '지식산업센터': 'Knowledge Industry Center',\n",
    "    '할인마트': 'Discount Mart',\n",
    "    '호텔및리조트': 'Hotel and Resort'\n",
    "}\n",
    "\n",
    "building_info['building_type'] = building_info['building_type'].replace(translation_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088cd6cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-01T09:55:55.432003Z",
     "start_time": "2023-09-01T09:55:55.418991Z"
    }
   },
   "outputs": [],
   "source": [
    "building_info['solar_power_utility'] = np.where(building_info.solar_power_capacity !='-',1,0)\n",
    "building_info['ess_utility'] = np.where(building_info.ess_capacity !='-',1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fef2583",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-01T09:55:55.597153Z",
     "start_time": "2023-09-01T09:55:55.569128Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.merge(train, building_info, on='building_number', how='left')\n",
    "test = pd.merge(test, building_info, on='building_number', how='left')\n",
    "\n",
    "# 🔹 여기서 냉방면적비 추가\n",
    "train[\"cooling_ratio\"] = (\n",
    "    train[\"cooling_area\"] / train[\"total_area\"]\n",
    ").replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "\n",
    "test[\"cooling_ratio\"] = (\n",
    "    test[\"cooling_area\"] / test[\"total_area\"]\n",
    ").replace([np.inf, -np.inf], np.nan).fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b38f22",
   "metadata": {},
   "source": [
    "## 결측치 확인 및 보간"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17a6966",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-01T09:55:56.422564Z",
     "start_time": "2023-09-01T09:55:56.389534Z"
    }
   },
   "outputs": [],
   "source": [
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d88de08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-01T09:55:56.857370Z",
     "start_time": "2023-09-01T09:55:56.835349Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train.solar_power_capacity.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e4059d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-01T09:55:57.172845Z",
     "start_time": "2023-09-01T09:55:57.161836Z"
    }
   },
   "outputs": [],
   "source": [
    "train.ess_capacity.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70841b49",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-01T09:55:57.368025Z",
     "start_time": "2023-09-01T09:55:57.351010Z"
    }
   },
   "outputs": [],
   "source": [
    "train.pcs_capacity.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ca69ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['windspeed']= train.windspeed.interpolate()\n",
    "train['humidity']= train.humidity.interpolate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebba91d",
   "metadata": {},
   "source": [
    "## Datetime 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a48c18d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-01T09:55:58.103624Z",
     "start_time": "2023-09-01T09:55:57.991522Z"
    }
   },
   "outputs": [],
   "source": [
    "train['date_time'] = pd.to_datetime(train['date_time'], format='%Y%m%d %H')\n",
    "\n",
    "# date time feature 생성\n",
    "train['hour'] = train['date_time'].dt.hour\n",
    "train['day'] = train['date_time'].dt.day\n",
    "train['month'] = train['date_time'].dt.month\n",
    "train['day_of_week'] = train['date_time'].dt.dayofweek #요일\n",
    "\n",
    "\n",
    "test['date_time'] = pd.to_datetime(test['date_time'], format='%Y%m%d %H')\n",
    "\n",
    "# date time feature 생성\n",
    "test['hour'] = test['date_time'].dt.hour\n",
    "test['day'] = test['date_time'].dt.day\n",
    "test['month'] = test['date_time'].dt.month\n",
    "test['day_of_week'] = test['date_time'].dt.dayofweek #요일"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4cc4133",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c342c005",
   "metadata": {},
   "source": [
    "### 평균기온, 최대기온 변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790fec52",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-01T09:56:20.587052Z",
     "start_time": "2023-09-01T09:55:58.499939Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_day_values(dataframe, target_column, output_column, aggregation_func):\n",
    "    result_dict = {}\n",
    "\n",
    "    grouped_temp = dataframe.groupby(['building_number', 'month', 'day'])[target_column].agg(aggregation_func)\n",
    "\n",
    "    for (building, month, day), value in grouped_temp.items():\n",
    "        result_dict.setdefault(building, {}).setdefault(month, {})[day] = value\n",
    "\n",
    "    dataframe[output_column] = [\n",
    "        result_dict.get(row['building_number'], {}).get(row['month'], {}).get(row['day'], None)\n",
    "        for _, row in dataframe.iterrows()\n",
    "    ]\n",
    "\n",
    "    \n",
    "train['day_max_temperature'] = 0.0\n",
    "train['day_mean_temperature'] = 0.0\n",
    "\n",
    "calculate_day_values(train, 'temperature', 'day_max_temperature', 'max')\n",
    "calculate_day_values(train, 'temperature', 'day_mean_temperature', 'mean')\n",
    "calculate_day_values(train, 'temperature', 'day_min_temperature', 'min')\n",
    "\n",
    "train['day_temperature_range'] = train['day_max_temperature'] - train['day_min_temperature']\n",
    "\n",
    "calculate_day_values(test, 'temperature', 'day_max_temperature', 'max')\n",
    "calculate_day_values(test, 'temperature', 'day_mean_temperature', 'mean')\n",
    "calculate_day_values(test, 'temperature', 'day_min_temperature', 'min')\n",
    "\n",
    "test['day_temperature_range'] = test['day_max_temperature'] - test['day_min_temperature']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2432f9f8",
   "metadata": {},
   "source": [
    "### Outlier drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3a4e6d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-01T09:56:20.617080Z",
     "start_time": "2023-09-01T09:56:20.588053Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.tsa.seasonal import STL\n",
    "\n",
    "# =========================================\n",
    "# 0) 유틸: 안전한 zscore (robust: median/MAD)\n",
    "# =========================================\n",
    "def robust_zscore(x):\n",
    "    med = np.nanmedian(x)\n",
    "    mad = np.nanmedian(np.abs(x - med)) + 1e-9\n",
    "    return (x - med) / (1.4826 * mad)\n",
    "\n",
    "# =========================================\n",
    "# 1) 규칙 기반: 연속 0(혹은 거의 0) runs\n",
    "# =========================================\n",
    "def detect_consecutive_runs(df, col='power_consumption', run_len=4, thresh=1e-6):\n",
    "    \"\"\"\n",
    "    건물별로 date_time 기준 정렬되어 있다고 가정.\n",
    "    run_len 시간 이상 연속으로 col <= thresh 인 구간의 '해당 구간 인덱스'를 반환\n",
    "    \"\"\"\n",
    "    bad_idx = []\n",
    "    for b, bdf in df.groupby('building_number'):\n",
    "        bdf = bdf.sort_values('date_time')\n",
    "        mask = (bdf[col] <= thresh).astype(int)\n",
    "        # 연속 구간 찾기\n",
    "        # run_id는 연속 구간마다 같은 번호를 갖도록 변환\n",
    "        changes = mask.diff().fillna(0) != 0\n",
    "        run_id = changes.cumsum()\n",
    "        # 각 run_id별 길이 계산 (0인 구간도 포함되므로 mask==1인 구간만 고려)\n",
    "        runs = bdf.assign(run_id=run_id)\n",
    "        runs = runs[mask == 1]\n",
    "        if runs.empty:\n",
    "            continue\n",
    "        lengths = runs.groupby('run_id').size()\n",
    "        long_runs = lengths[lengths >= run_len].index\n",
    "        out = runs[runs['run_id'].isin(long_runs)].index.tolist()\n",
    "        bad_idx.extend(out)\n",
    "    return bad_idx\n",
    "\n",
    "# =========================================\n",
    "# 2) STL 분해 → 잔차 계산\n",
    "# =========================================\n",
    "def stl_residuals_per_building(df, col='power_consumption', period=24):\n",
    "    \"\"\"\n",
    "    건물별로 시계열을 STL 분해하고 residual을 반환\n",
    "    period=24 (일주기), 주중/주말까지 강하면 24*7 고려\n",
    "    \"\"\"\n",
    "    residual = pd.Series(index=df.index, dtype=float)\n",
    "    for b, bdf in df.groupby('building_number'):\n",
    "        bdf = bdf.sort_values('date_time')\n",
    "        y = bdf[col].astype(float).values\n",
    "        # 길이가 period*2 이상이어야 STL 안정적\n",
    "        if len(y) < period * 2:\n",
    "            residual.loc[bdf.index] = np.nan\n",
    "            continue\n",
    "        try:\n",
    "            stl = STL(y, period=period, robust=True)\n",
    "            res = stl.fit()\n",
    "            resid = y - (res.trend + res.seasonal)\n",
    "            residual.loc[bdf.index] = resid\n",
    "        except Exception:\n",
    "            residual.loc[bdf.index] = np.nan\n",
    "    return residual\n",
    "\n",
    "# =========================================\n",
    "# 3) Hampel 필터 (잔차 대상)\n",
    "# =========================================\n",
    "def hampel_outliers(series, window=24, n_sigma=3.0):\n",
    "    \"\"\"\n",
    "    롤링 중앙값/ MAD 기반 Hampel: |x - med| / (1.4826*MAD) > n_sigma 이면 이상치\n",
    "    window는 계절주기(24) 또는 그 배수 추천\n",
    "    \"\"\"\n",
    "    x = series.astype(float).copy()\n",
    "    # pandas의 rolling median/MAD\n",
    "    med = x.rolling(window, center=True, min_periods=window//2).median()\n",
    "    abs_dev = (x - med).abs()\n",
    "    mad = abs_dev.rolling(window, center=True, min_periods=window//2).median()\n",
    "    z = (x - med) / (1.4826 * (mad + 1e-9))\n",
    "    return series.index[np.abs(z) > n_sigma].tolist()\n",
    "\n",
    "# =========================================\n",
    "# 4) 잔차에 robust z-score (간단 ESD 대용)\n",
    "# =========================================\n",
    "def residual_zscore_outliers(series, z_thresh=4.0):\n",
    "    z = robust_zscore(series.values)\n",
    "    return series.index[np.abs(z) > z_thresh].tolist()\n",
    "\n",
    "\n",
    "# === (ADD) 완화형: 이벤트성은 살리고 정전/센서 오류만 드롭 ===\n",
    "RELAX_TYPES = [\"Public\", \"Other Buildings\", \"호텔\", \"백화점\"]\n",
    "\n",
    "def build_outlier_list_relaxed(train,\n",
    "                               value_col='power_consumption',\n",
    "                               run_len=4,\n",
    "                               zero_thresh=1e-6,\n",
    "                               stl_period=24,\n",
    "                               hampel_window=24,\n",
    "                               hampel_sigma_relax=5.0,  # 완화 타입\n",
    "                               hampel_sigma_base=3.0,   # 일반 타입\n",
    "                               resid_z_relax=7.0,       # 완화 타입\n",
    "                               resid_z_base=4.0,        # 일반 타입\n",
    "                               use_weekly=False):\n",
    "    \"\"\"\n",
    "    반환: (drop_idx, extreme_idx)\n",
    "      - drop_idx: 실제 삭제(정전/센서오류 + (완화 아님 타입의 이벤트성))\n",
    "      - extreme_idx: 삭제 안 하고 is_extreme=1로 표시(완화 타입의 이벤트성)\n",
    "    \"\"\"\n",
    "    df = train.copy()\n",
    "    assert 'building_type' in df.columns, \"train에 building_type 필요\"\n",
    "    df['date_time'] = pd.to_datetime(df['date_time'])\n",
    "    df = df.sort_values(['building_type','building_number','date_time'])\n",
    "\n",
    "    drop_idx, extreme_idx = set(), set()\n",
    "\n",
    "    # 전체 상위 가드(말도 안되게 큰 값 컷)\n",
    "    try:\n",
    "        absurd_hi = np.nanpercentile(df[value_col], 99.9) * 5.0\n",
    "        if not np.isfinite(absurd_hi): absurd_hi = None\n",
    "    except Exception:\n",
    "        absurd_hi = None\n",
    "\n",
    "    for btype, g in df.groupby('building_type'):\n",
    "        # 1) 연속 0(run) → 정전/센서오류: 무조건 drop\n",
    "        o1 = detect_consecutive_runs(g, col=value_col, run_len=run_len, thresh=zero_thresh)\n",
    "\n",
    "        # 2) STL 잔차 기반 이벤트성 후보\n",
    "        resid_daily = stl_residuals_per_building(g, col=value_col, period=stl_period)\n",
    "        if btype in RELAX_TYPES:\n",
    "            hs, rz = hampel_sigma_relax, resid_z_relax\n",
    "        else:\n",
    "            hs, rz = hampel_sigma_base, resid_z_base\n",
    "\n",
    "        o2 = hampel_outliers(resid_daily, window=hampel_window, n_sigma=hs)\n",
    "        o3 = residual_zscore_outliers(resid_daily.dropna(), z_thresh=rz)\n",
    "\n",
    "        if use_weekly:\n",
    "            resid_week = stl_residuals_per_building(g, col=value_col, period=24*7)\n",
    "            o4 = hampel_outliers(resid_week, window=24*7, n_sigma=hs)\n",
    "            o5 = residual_zscore_outliers(resid_week.dropna(), z_thresh=rz)\n",
    "        else:\n",
    "            o4, o5 = [], []\n",
    "\n",
    "        event_like  = set(o2) | set(o3) | set(o4) | set(o5)\n",
    "\n",
    "        # 3) 센서/정전 직접 규칙(0, 음수, 급락, 황당히 큰 값)\n",
    "        sub = g[value_col].astype(float)\n",
    "        outage_mask = (sub <= zero_thresh) | (sub < 0)\n",
    "        if absurd_hi is not None:\n",
    "            outage_mask |= (sub > absurd_hi)\n",
    "        prev = sub.shift(1)\n",
    "        drop_mask = (prev > 0) & ((prev - sub) / (prev + 1e-9) >= 0.95)\n",
    "        sensor_like = set(g.index[outage_mask | drop_mask])\n",
    "\n",
    "        if btype in RELAX_TYPES:\n",
    "            # 완화 타입: 센서는 drop, 이벤트성은 살려서 플래그\n",
    "            drop_idx |= sensor_like\n",
    "            extreme_idx |= (event_like - sensor_like)\n",
    "        else:\n",
    "            # 일반 타입: 이벤트성도 drop\n",
    "            drop_idx |= (sensor_like | event_like)\n",
    "\n",
    "        # (선택) 과도 제거 방지: 건물별 2%\n",
    "        for bn, bdf in g.groupby('building_number'):\n",
    "            b_out = list(set(bdf.index) & drop_idx)\n",
    "            max_keep = int(0.02 * len(bdf))\n",
    "            if len(b_out) > max_keep and max_keep > 0:\n",
    "                keep_back = set(bdf.index) & drop_idx\n",
    "                # 단순 상한 적용(원하면 |잔차| 기준 정렬해도 됨)\n",
    "                keep_back = set(list(keep_back)[:max_keep])\n",
    "                drop_idx -= ((set(bdf.index) & drop_idx) - keep_back)\n",
    "\n",
    "    return sorted(list(drop_idx)), sorted(list(extreme_idx))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c115bdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_idx, extreme_idx = build_outlier_list_relaxed(\n",
    "    train,\n",
    "    value_col='power_consumption',\n",
    "    run_len=4,\n",
    "    zero_thresh=1e-6,\n",
    "    stl_period=24,\n",
    "    hampel_window=24,\n",
    "    hampel_sigma_relax=5.0,  # 완화\n",
    "    hampel_sigma_base=3.0,   # 기본\n",
    "    resid_z_relax=7.0,       # 완화\n",
    "    resid_z_base=4.0,        # 기본\n",
    "    use_weekly=True\n",
    ")\n",
    "print(f\"삭제(drop): {len(drop_idx)} | 이벤트성 표시(extreme): {len(extreme_idx)}\")\n",
    "\n",
    "# 플래그 추가 + 드롭 적용\n",
    "train_marked = train.copy()\n",
    "train_marked[\"is_extreme\"] = 0\n",
    "train_marked.loc[extreme_idx, \"is_extreme\"] = 1\n",
    "\n",
    "train = train_marked.drop(index=drop_idx).reset_index(drop=True)\n",
    "\n",
    "# 테스트에는 플래그 0으로 생성\n",
    "if \"is_extreme\" not in test.columns:\n",
    "    test[\"is_extreme\"] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ba59e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-18T07:59:24.686619Z",
     "start_time": "2023-08-18T07:59:24.676611Z"
    }
   },
   "source": [
    "### 임시 휴무 추측 데이터 drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085c71db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-01T09:56:21.742893Z",
     "start_time": "2023-09-01T09:56:20.618081Z"
    }
   },
   "outputs": [],
   "source": [
    "# temp_hol = {2 : ['2022-06-17'], \n",
    "#     5 : ['2022-07-25','2022-08-02','2022-08-09','2022-08-16'],\n",
    "#     11 : ['2022-06-17'], 12 : ['2022-07-02'], 17 : ['2022-06-18','2022-07-25'],\n",
    "#     21 : ['2022-07-01','2022-07-03','2022-07-17','2022-07-30'], \n",
    "#     37 : ['2022-06-20','2022-07-11','2022-08-08'], \n",
    "#     38 : ['2022-06-13','2022-07-25','2022-08-01'],\n",
    "#     39 : ['2022-07-18','2022-08-08'],\n",
    "#     40 : ['2022-06-20','2022-07-18','2022-08-08'],\n",
    "#     41 : ['2022-06-27','2022-07-25','2022-08-08'],\n",
    "#     42 : ['2022-06-13','2022-07-11','2022-08-22'],\n",
    "#     54 : ['2022-08-16','2022-08-17'],74 : ['2022-06-03'],\n",
    "#     75 : ['2022-06-15','2022-06-17','2022-06-20','2022-06-21'],\n",
    "#     86 : ['2022-06-10','2022-08-10'],\n",
    "#     89 : ['2022-07-09'], 91 : ['2022-06-13','2022-07-11','2022-08-22','2022-06-08'], 92 : ['2022-07-30']}\n",
    "\n",
    "\n",
    "# mask = train.apply(lambda x: x['building_number'] in temp_hol and str(x['date_time'])[:10] in temp_hol[x['building_number']], axis=1)\n",
    "\n",
    "# train.drop(train[mask].index, axis=0, inplace=True)\n",
    "\n",
    "# train.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af13843",
   "metadata": {},
   "source": [
    "### 공휴일변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de0a595",
   "metadata": {},
   "outputs": [],
   "source": [
    "holi_weekday = [\n",
    "    '2024-06-06',  # 현충일 (목)\n",
    "    '2024-08-15'   # 광복절 (목)\n",
    "]\n",
    "\n",
    "train['holiday'] = np.where((train.day_of_week >= 5) | (train.date_time.dt.strftime('%Y-%m-%d').isin(holi_weekday)), 1, 0)\n",
    "test['holiday'] = np.where((test.day_of_week >= 5) | (test.date_time.dt.strftime('%Y-%m-%d').isin(holi_weekday)), 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11ae359",
   "metadata": {},
   "source": [
    "### 대형마트 휴무일요일 변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4452ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "holi_sun = [\n",
    "    '2024-06-09', '2024-06-23',  # 6월\n",
    "    '2024-07-14', '2024-07-28',  # 7월\n",
    "    '2024-08-11', '2024-08-25'   # 8월\n",
    "]\n",
    "\n",
    "# 의무 휴업 일요일이면 1, 아니면 0\n",
    "train['Sunday_holiday'] = np.where((train.day_of_week == 6) & (train.date_time.dt.strftime('%Y-%m-%d').isin(holi_sun)), 1, 0)\n",
    "test['Sunday_holiday'] = np.where((test.day_of_week == 6) & (test.date_time.dt.strftime('%Y-%m-%d').isin(holi_sun)), 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830eb712",
   "metadata": {},
   "source": [
    "### 시간변수 푸리에변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6e2c69",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-01T09:56:21.998125Z",
     "start_time": "2023-09-01T09:56:21.954085Z"
    }
   },
   "outputs": [],
   "source": [
    "#시간\n",
    "train['sin_hour'] = np.sin(2 * np.pi * train['hour']/23.0)\n",
    "train['cos_hour'] = np.cos(2 * np.pi * train['hour']/23.0)\n",
    "test['sin_hour'] = np.sin(2 * np.pi * test['hour']/23.0)\n",
    "test['cos_hour'] = np.cos(2 * np.pi * test['hour']/23.0)\n",
    "\n",
    "#날짜\n",
    "train['sin_date'] = -np.sin(2 * np.pi * (train['month']+train['day']/31)/12)\n",
    "train['cos_date'] = -np.cos(2 * np.pi * (train['month']+train['day']/31)/12)\n",
    "test['sin_date'] = -np.sin(2 * np.pi * (test['month']+test['day']/31)/12)\n",
    "test['cos_date'] = -np.cos(2 * np.pi * (test['month']+test['day']/31)/12)\n",
    "\n",
    "#월\n",
    "train['sin_month'] = -np.sin(2 * np.pi * train['month']/12.0)\n",
    "train['cos_month'] = -np.cos(2 * np.pi * train['month']/12.0)\n",
    "test['sin_month'] = -np.sin(2 * np.pi * test['month']/12.0)\n",
    "test['cos_month'] = -np.cos(2 * np.pi * test['month']/12.0)\n",
    "\n",
    "#요일\n",
    "train['sin_dayofweek'] = -np.sin(2 * np.pi * (train['day_of_week']+1)/7.0)\n",
    "train['cos_dayofweek'] = -np.cos(2 * np.pi * (train['day_of_week']+1)/7.0)\n",
    "test['sin_dayofweek'] = -np.sin(2 * np.pi * (test['day_of_week']+1)/7.0)\n",
    "test['cos_dayofweek'] = -np.cos(2 * np.pi * (test['day_of_week']+1)/7.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04681b67",
   "metadata": {},
   "source": [
    "### CDH(냉방도시) 변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137ebec3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-01T09:56:22.133621Z",
     "start_time": "2023-09-01T09:56:21.999126Z"
    }
   },
   "outputs": [],
   "source": [
    "def CDH(xs):\n",
    "    cumsum = np.cumsum(xs - 26)\n",
    "    return np.concatenate((cumsum[:11], cumsum[11:] - cumsum[:-11]))\n",
    "\n",
    "def calculate_and_add_cdh(dataframe):\n",
    "    cdhs = []\n",
    "    for i in range(1, 101):\n",
    "        temp = dataframe[dataframe['building_number'] == i]['temperature'].values\n",
    "        cdh = CDH(temp)\n",
    "        cdhs.append(cdh)\n",
    "    return np.concatenate(cdhs)\n",
    "\n",
    "train['CDH'] = calculate_and_add_cdh(train)\n",
    "test['CDH'] = calculate_and_add_cdh(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2928f6",
   "metadata": {},
   "source": [
    "### THI(불쾌지수) 변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b733555",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-01T09:56:22.148635Z",
     "start_time": "2023-09-01T09:56:22.133621Z"
    }
   },
   "outputs": [],
   "source": [
    "train['THI'] = 9/5*train['temperature'] - 0.55*(1-train['humidity']/100)*(9/5*train['humidity']-26)+32\n",
    "\n",
    "test['THI'] = 9/5*test['temperature'] - 0.55*(1-test['humidity']/100)*(9/5*test['humidity']-26)+32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03e6e19",
   "metadata": {},
   "source": [
    "### WCT(체감온도) 변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cdf79c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-01T09:56:22.163649Z",
     "start_time": "2023-09-01T09:56:22.149636Z"
    }
   },
   "outputs": [],
   "source": [
    "train['WCT'] = 13.12 + 0.6125*train['temperature'] - 11.37*(train['windspeed']**\n",
    "                                                            0.16) + 0.3965*(train['windspeed']**0.16)*train['temperature']\n",
    "test['WCT'] = 13.12 + 0.6125*test['temperature'] - 11.37*(test['windspeed']**\n",
    "                                                            0.16) + 0.3965*(test['windspeed']**0.16)*test['temperature']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec1ab63",
   "metadata": {},
   "source": [
    "### 전력소비 통계량 변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179c6408",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-01T09:56:22.403867Z",
     "start_time": "2023-09-01T09:56:22.164649Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate 'day_hour_mean'\n",
    "power_mean = pd.pivot_table(train, values='power_consumption', index=['building_number', 'hour', 'day_of_week'], aggfunc=np.mean).reset_index()\n",
    "power_mean.columns = ['building_number', 'hour', 'day_of_week', 'day_hour_mean']\n",
    "\n",
    "# Calculate 'day_hour_std'\n",
    "power_std = pd.pivot_table(train, values='power_consumption', index=['building_number', 'hour', 'day_of_week'], aggfunc=np.std).reset_index()\n",
    "power_std.columns = ['building_number', 'hour', 'day_of_week', 'day_hour_std']\n",
    "\n",
    "# Calculate 'hour_mean'\n",
    "power_hour_mean = pd.pivot_table(train, values='power_consumption', index=['building_number', 'hour'], aggfunc=np.mean).reset_index()\n",
    "power_hour_mean.columns = ['building_number', 'hour', 'hour_mean']\n",
    "\n",
    "# Calculate 'hour_std'\n",
    "power_hour_std = pd.pivot_table(train, values='power_consumption', index=['building_number', 'hour'], aggfunc=np.std).reset_index()\n",
    "power_hour_std.columns = ['building_number', 'hour', 'hour_std']\n",
    "\n",
    "# Merge calculated features to 'train' and 'test' dataframes\n",
    "train = train.merge(power_mean, on=['building_number', 'hour', 'day_of_week'], how='left')\n",
    "test = test.merge(power_mean, on=['building_number', 'hour', 'day_of_week'], how='left')\n",
    "\n",
    "train = train.merge(power_std, on=['building_number', 'hour', 'day_of_week'], how='left')\n",
    "test = test.merge(power_std, on=['building_number', 'hour', 'day_of_week'], how='left')\n",
    "\n",
    "train = train.merge(power_hour_mean, on=['building_number', 'hour'], how='left')\n",
    "test = test.merge(power_hour_mean, on=['building_number', 'hour'], how='left')\n",
    "\n",
    "train = train.merge(power_hour_std, on=['building_number', 'hour'], how='left')\n",
    "test = test.merge(power_hour_std, on=['building_number', 'hour'], how='left')\n",
    "\n",
    "train = train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a8f9f2",
   "metadata": {},
   "source": [
    "# 모델링"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2598b0",
   "metadata": {},
   "source": [
    "## X,Y,test 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b32510f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-01T09:56:22.418880Z",
     "start_time": "2023-09-01T09:56:22.404867Z"
    }
   },
   "outputs": [],
   "source": [
    "X = train.drop(['solar_power_capacity', 'ess_capacity', 'pcs_capacity',\n",
    "                'power_consumption','rainfall', 'sunshine', 'solar_radiation',\n",
    "                'hour','day','month','day_of_week','date_time'],axis =1 )\n",
    "\n",
    "Y = train[['building_type','power_consumption']]\n",
    "\n",
    "test_X = test.drop(['solar_power_capacity', 'ess_capacity', 'pcs_capacity','rainfall',\n",
    "                   'hour','month','day_of_week','day','date_time'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b195ec8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-01T12:07:56.459743Z",
     "start_time": "2023-09-01T12:07:56.428037Z"
    }
   },
   "outputs": [],
   "source": [
    "type_list = []\n",
    "for value in train.building_type.values:\n",
    "    if value not in type_list:\n",
    "        type_list.append(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628caf04",
   "metadata": {},
   "source": [
    "## XGB 건물 유형별 단일모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c995f9d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-01T12:07:57.662804Z",
     "start_time": "2023-09-01T12:07:57.656785Z"
    }
   },
   "outputs": [],
   "source": [
    "xgb_best_params = pd.read_csv('xgb_best_params_found.csv')\n",
    "xgb_best_params['building_type'] = type_list\n",
    "xgb_best_params.set_index('building_type',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ae3886",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-01T12:07:58.803898Z",
     "start_time": "2023-09-01T12:07:58.786884Z"
    }
   },
   "outputs": [],
   "source": [
    "xgb_best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851f3da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 글로벌 모델 파라미터 (전체 데이터로 학습할 모델)\n",
    "global_xgb_params = {\n",
    "    'learning_rate': 0.05,\n",
    "    'n_estimators': 5000,\n",
    "    'max_depth': 8,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'min_child_weight': 3,\n",
    "    'alpha': 1.5,  # weighted_mse 파라미터\n",
    "    'random_state': RANDOM_SEED,\n",
    "    'tree_method': 'gpu_hist'\n",
    "}\n",
    "\n",
    "# 앙상블 가중치 설정 (타입별:글로벌 = 7:3 비율)\n",
    "ENSEMBLE_WEIGHT_TYPE = 0.7  # 타입별 모델 가중치\n",
    "ENSEMBLE_WEIGHT_GLOBAL = 0.3  # 글로벌 모델 가중치\n",
    "\n",
    "print(f\"앙상블 가중치 - 타입별 모델: {ENSEMBLE_WEIGHT_TYPE}, 글로벌 모델: {ENSEMBLE_WEIGHT_GLOBAL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897f4175",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-30T11:40:03.076892Z",
     "start_time": "2023-08-30T10:49:46.245401Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=7, shuffle=True, random_state=RANDOM_SEED)\n",
    "\n",
    "# 결과 저장용 DataFrame\n",
    "answer_df = pd.DataFrame(columns=['answer'])\n",
    "pred_df = pd.DataFrame(columns=['pred'])\n",
    "\n",
    "# 글로벌 모델 결과 저장용\n",
    "global_answer_df = pd.DataFrame(columns=['answer'])\n",
    "global_pred_df = pd.DataFrame(columns=['pred'])\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"1단계: 글로벌 모델 학습\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# ===== 글로벌 모델 학습 =====\n",
    "X_global = X.copy()\n",
    "Y_global = Y['power_consumption'].astype(float).copy()\n",
    "X_test_global = test_X.copy()\n",
    "\n",
    "# 글로벌 모델용 데이터 정리\n",
    "Y_global = Y_global.replace([np.inf, -np.inf], np.nan)\n",
    "ok_global = Y_global.notna() & (Y_global >= 0)\n",
    "if not ok_global.all():\n",
    "    X_global = X_global.loc[ok_global]\n",
    "    Y_global = Y_global.loc[ok_global]\n",
    "\n",
    "# 원핫 인코딩\n",
    "X_global = pd.get_dummies(X_global, columns=['building_number', 'building_type'], drop_first=False)\n",
    "X_test_global = pd.get_dummies(X_test_global, columns=['building_number', 'building_type'], drop_first=False)\n",
    "\n",
    "# train/test 컬럼 정렬\n",
    "X_global, X_test_global = X_global.align(X_test_global, join='outer', axis=1, fill_value=0)\n",
    "\n",
    "# NaN/Inf 처리\n",
    "X_global = X_global.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "X_test_global = X_test_global.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "\n",
    "# 데이터 타입 정리\n",
    "X_global = X_global.astype(np.float32)\n",
    "Y_global = Y_global.astype(np.float32)\n",
    "\n",
    "# 글로벌 모델 교차검증\n",
    "global_fold_smape = []\n",
    "global_answer_list = []\n",
    "global_pred = pd.DataFrame(index=Y_global.index.copy(), columns=['pred'])\n",
    "\n",
    "j = 0\n",
    "for train_index, valid_index in kf.split(X_global):\n",
    "    j += 1\n",
    "    print(f\"글로벌 모델 - Fold {j}/{kf.n_splits}\")\n",
    "    \n",
    "    X_train, X_valid = X_global.iloc[train_index], X_global.iloc[valid_index]\n",
    "    Y_train, Y_valid = Y_global.iloc[train_index], Y_global.iloc[valid_index]\n",
    "    \n",
    "    # log1p 변환\n",
    "    Y_train_t = np.log1p(np.clip(Y_train, a_min=0, a_max=None))\n",
    "    Y_valid_t = np.log1p(np.clip(Y_valid, a_min=0, a_max=None))\n",
    "    \n",
    "    evals = [(X_train, Y_train_t), (X_valid, Y_valid_t)]\n",
    "    \n",
    "    global_model = XGBRegressor(\n",
    "        learning_rate=global_xgb_params['learning_rate'],\n",
    "        n_estimators=global_xgb_params['n_estimators'],\n",
    "        max_depth=global_xgb_params['max_depth'],\n",
    "        random_state=global_xgb_params['random_state'],\n",
    "        subsample=global_xgb_params['subsample'],\n",
    "        colsample_bytree=global_xgb_params['colsample_bytree'],\n",
    "        min_child_weight=global_xgb_params['min_child_weight'],\n",
    "        objective=weighted_mse(global_xgb_params['alpha']),\n",
    "        tree_method=global_xgb_params['tree_method'],\n",
    "    )\n",
    "    \n",
    "    global_model.fit(\n",
    "        X_train, Y_train_t,\n",
    "        early_stopping_rounds=100,\n",
    "        eval_metric=custom_smape,\n",
    "        eval_set=evals,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    # 검증 예측\n",
    "    global_pred_t = global_model.predict(X_valid)\n",
    "    global_pred_val = np.expm1(global_pred_t)\n",
    "    global_pred.loc[Y_valid.index, 'pred'] = global_pred_val\n",
    "    \n",
    "    # SMAPE 계산\n",
    "    global_smape = smape(Y_valid.values, global_pred_val)\n",
    "    global_fold_smape.append(global_smape)\n",
    "    \n",
    "    # 테스트 예측\n",
    "    global_answer_t = global_model.predict(X_test_global)\n",
    "    global_answer_list.append(np.expm1(global_answer_t))\n",
    "\n",
    "# 글로벌 모델 결과\n",
    "global_type_answer = sum(global_answer_list) / len(global_answer_list)\n",
    "global_answer = pd.DataFrame({'answer': global_type_answer}, index=X_test_global.index)\n",
    "global_answer_df = pd.concat([global_answer_df, global_answer], axis=0)\n",
    "global_pred_df = pd.concat([global_pred_df, global_pred], axis=0)\n",
    "\n",
    "global_avg_smape = sum(global_fold_smape) / len(global_fold_smape)\n",
    "print(f'글로벌 모델 SMAPE : {global_avg_smape:.4f}')\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"2단계: 건물 타입별 모델 학습\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# ===== 타입별 모델 학습 (기존 코드) =====\n",
    "for i in type_list:\n",
    "    print(f\"\\n건물 타입: {i}\")\n",
    "    \n",
    "    # 데이터 준비\n",
    "    x = X[X.building_type == i].copy()\n",
    "    y = Y[Y.building_type == i]['power_consumption'].astype(float).copy()\n",
    "    X_test_i = test_X[test_X.building_type == i].copy()\n",
    "\n",
    "    # 라벨 클린업\n",
    "    y = y.replace([np.inf, -np.inf], np.nan)\n",
    "    ok = y.notna() & (y >= 0)\n",
    "    if not ok.all():\n",
    "        x = x.loc[ok]\n",
    "        y = y.loc[ok]\n",
    "\n",
    "    # 원핫 인코딩\n",
    "    x = pd.get_dummies(x, columns=['building_number'], drop_first=False)\n",
    "    X_test_i = pd.get_dummies(X_test_i, columns=['building_number'], drop_first=False)\n",
    "\n",
    "    # 불필요 컬럼 제거\n",
    "    for df_ in (x, X_test_i):\n",
    "        if 'building_type' in df_.columns:\n",
    "            df_.drop(columns=['building_type'], inplace=True)\n",
    "\n",
    "    # train/test 더미 컬럼 정렬\n",
    "    x, X_test_i = x.align(X_test_i, join='outer', axis=1, fill_value=0)\n",
    "\n",
    "    # NaN/Inf 처리\n",
    "    x = x.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "    X_test_i = X_test_i.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "\n",
    "    # 컬럼명 저장\n",
    "    x_columns = np.array(x.columns)\n",
    "\n",
    "    # 데이터 타입 정리\n",
    "    x = x.astype(np.float32)\n",
    "    y = y.astype(np.float32)\n",
    "\n",
    "    j = 0\n",
    "    xgb_fold_smape = []\n",
    "    answer_list = []\n",
    "\n",
    "    # OOF 그릇 생성\n",
    "    pred = pd.DataFrame(index=y.index.copy(), columns=['pred'])\n",
    "\n",
    "    for train_index, valid_index in kf.split(x):\n",
    "        j += 1\n",
    "\n",
    "        X_train, X_valid = x.iloc[train_index], x.iloc[valid_index]\n",
    "        Y_train, Y_valid = y.iloc[train_index], y.iloc[valid_index]\n",
    "\n",
    "        # log1p 변환\n",
    "        Y_train_t = np.log1p(np.clip(Y_train, a_min=0, a_max=None))\n",
    "        Y_valid_t = np.log1p(np.clip(Y_valid, a_min=0, a_max=None))\n",
    "\n",
    "        evals = [(X_train, Y_train_t), (X_valid, Y_valid_t)]\n",
    "\n",
    "        xgb_model = XGBRegressor(\n",
    "            learning_rate=0.05,\n",
    "            n_estimators=5000,\n",
    "            max_depth=int(xgb_best_params.loc[i]['max_depth']),\n",
    "            random_state=RANDOM_SEED,\n",
    "            subsample=xgb_best_params.loc[i]['subsample'],\n",
    "            colsample_bytree=xgb_best_params.loc[i]['colsample_bytree'],\n",
    "            min_child_weight=int(xgb_best_params.loc[i]['min_child_weight']),\n",
    "            objective=weighted_mse(xgb_best_params.loc[i]['alpha']),\n",
    "            tree_method='gpu_hist',\n",
    "        )\n",
    "\n",
    "        xgb_model.fit(\n",
    "            X_train, Y_train_t,\n",
    "            early_stopping_rounds=100,\n",
    "            eval_metric=custom_smape,\n",
    "            eval_set=evals,\n",
    "            verbose=False\n",
    "        )\n",
    "\n",
    "        # 검증 예측\n",
    "        xgb_pred_t = xgb_model.predict(X_valid)\n",
    "        xgb_pred = np.expm1(xgb_pred_t)\n",
    "        pred.loc[Y_valid.index, 'pred'] = xgb_pred\n",
    "\n",
    "        # SMAPE 계산\n",
    "        xgb_smape = smape(Y_valid.values, xgb_pred)\n",
    "        xgb_fold_smape.append(xgb_smape)\n",
    "\n",
    "        # 테스트 예측\n",
    "        xgb_answer_t = xgb_model.predict(X_test_i)\n",
    "        answer_list.append(np.expm1(xgb_answer_t))\n",
    "\n",
    "        # 마지막 폴드에서 중요도 그리기\n",
    "        if j == kf.n_splits:\n",
    "            sorted_idx = xgb_model.feature_importances_.argsort()\n",
    "            plt.figure(figsize=(8, 15))\n",
    "            plt.barh(x_columns[sorted_idx], xgb_model.feature_importances_[sorted_idx])\n",
    "            plt.xlabel(f'{i} model XGB Feature Importance')\n",
    "            plt.show()\n",
    "\n",
    "    # 타입별 테스트 평균\n",
    "    type_answer = sum(answer_list) / len(answer_list)\n",
    "    answer = pd.DataFrame({'answer': type_answer}, index=X_test_i.index)\n",
    "\n",
    "    # 결과 저장\n",
    "    answer_df = pd.concat([answer_df, answer], axis=0)\n",
    "    pred_df = pd.concat([pred_df, pred], axis=0)\n",
    "\n",
    "    avg_smape = sum(xgb_fold_smape) / len(xgb_fold_smape)\n",
    "    print(f'Building type = {i} : XGBRegressor Model SMAPE : {avg_smape:.4f}')\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"3단계: 앙상블 결과 계산\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# ===== 앙상블 계산 =====\n",
    "# 검증 데이터 앙상블 (SMAPE 계산용)\n",
    "ensemble_pred_df = pd.DataFrame(index=pred_df.index, columns=['pred'])\n",
    "for idx in pred_df.index:\n",
    "    if idx in global_pred_df.index:\n",
    "        type_pred = pred_df.loc[idx, 'pred']\n",
    "        global_pred_val = global_pred_df.loc[idx, 'pred']\n",
    "        ensemble_pred = (ENSEMBLE_WEIGHT_TYPE * type_pred + \n",
    "                        ENSEMBLE_WEIGHT_GLOBAL * global_pred_val)\n",
    "        ensemble_pred_df.loc[idx, 'pred'] = ensemble_pred\n",
    "    else:\n",
    "        ensemble_pred_df.loc[idx, 'pred'] = pred_df.loc[idx, 'pred']\n",
    "\n",
    "# 테스트 데이터 앙상블\n",
    "ensemble_answer_df = pd.DataFrame(index=answer_df.index, columns=['answer'])\n",
    "for idx in answer_df.index:\n",
    "    if idx in global_answer_df.index:\n",
    "        type_answer = answer_df.loc[idx, 'answer']\n",
    "        global_answer_val = global_answer_df.loc[idx, 'answer']\n",
    "        ensemble_answer = (ENSEMBLE_WEIGHT_TYPE * type_answer + \n",
    "                          ENSEMBLE_WEIGHT_GLOBAL * global_answer_val)\n",
    "        ensemble_answer_df.loc[idx, 'answer'] = ensemble_answer\n",
    "    else:\n",
    "        ensemble_answer_df.loc[idx, 'answer'] = answer_df.loc[idx, 'answer']\n",
    "\n",
    "# SMAPE 계산\n",
    "type_only_score = smape(\n",
    "    Y.loc[pred_df.index, 'power_consumption'].values.astype(float),\n",
    "    pred_df['pred'].values.astype(float)\n",
    ")\n",
    "\n",
    "ensemble_score = smape(\n",
    "    Y.loc[ensemble_pred_df.index, 'power_consumption'].values.astype(float),\n",
    "    ensemble_pred_df['pred'].values.astype(float)\n",
    ")\n",
    "\n",
    "print(f'타입별 모델만 사용한 Total SMAPE : {type_only_score:.4f}')\n",
    "print(f'글로벌 모델만 사용한 Total SMAPE : {global_avg_smape:.4f}')\n",
    "print(f'앙상블 모델 Total SMAPE : {ensemble_score:.4f}')\n",
    "print(f'성능 개선 : {type_only_score - ensemble_score:.4f}')\n",
    "\n",
    "# 기존 형식과 동일하게 출력\n",
    "print('Total SMAPE : %.4f' % (ensemble_score))\n",
    "\n",
    "# 최종 결과를 ensemble_answer_df로 설정\n",
    "answer_df = ensemble_answer_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282c4abc",
   "metadata": {},
   "source": [
    "## 정답파일 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ef13fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-30T11:44:33.046251Z",
     "start_time": "2023-08-30T11:44:33.033239Z"
    }
   },
   "outputs": [],
   "source": [
    "answer = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f959ba4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-30T11:44:33.226417Z",
     "start_time": "2023-08-30T11:44:33.210401Z"
    }
   },
   "outputs": [],
   "source": [
    "answer.answer = answer_df.answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcff61f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-30T11:44:33.676826Z",
     "start_time": "2023-08-30T11:44:33.653804Z"
    }
   },
   "outputs": [],
   "source": [
    "answer.to_csv('submission.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b51d62",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-01T12:18:33.109076Z",
     "start_time": "2023-09-01T12:18:33.095063Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "answer.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9974b3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "groom",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "286.188px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
